{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uOm80lIwZPh"
      },
      "source": [
        "Refer to the lectures, implement Bayesian classifier from scratch, use it on MNIST dataset, and test.\n",
        "\n",
        "Generate the confusion matrix and F1 score for each Dist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctJ-LD4VwYVP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn import preprocessing\n",
        "from keras.datasets import mnist\n",
        "from decimal import *\n",
        "from math import log, log10, exp, e, pow, sqrt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k80ADqyYfQSL"
      },
      "source": [
        "## Bayesian Classifier: Continuous Multivariate Distribution "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKjlxRNFfPuu"
      },
      "outputs": [],
      "source": [
        "class BayesianClassifier():\n",
        "\n",
        "   def __init__(self):\n",
        "     self.classes_num=0\n",
        "     self.features_num=0\n",
        "     self.mean_dict={}\n",
        "     self.Cov_dict={}\n",
        "     self.Cov_inv_dict={}\n",
        "     self.discriminant_functions=[]\n",
        "\n",
        "   def fit(self,training_data,samples_num): \n",
        "\n",
        "     self.classes_num= len(training_data)\n",
        "     self.features_num=len(training_data[0][0]);\n",
        "     identity=np.eye(self.features_num)\n",
        "\n",
        "\n",
        "     for k in range(0,self.classes_num):\n",
        "\n",
        "          current_samples_n= samples_num[k]\n",
        "          mean_array=[]\n",
        "          Cov_array=[]\n",
        "  \n",
        "          for i in range(0,self.features_num): \n",
        "             mean=0        \n",
        "             counter=0\n",
        "             variance=0\n",
        "             Cov= 0\n",
        "             Cov_inverse=0  \n",
        "             elements=[] \n",
        "              \n",
        "             for j in range(0,current_samples_n):\n",
        "               mean= mean+training_data[k][j][i]  \n",
        "               element= training_data[k][j][i]\n",
        "               elements.append(element)  \n",
        "               counter= counter+1 \n",
        "            \n",
        "             mean=mean/counter\n",
        "             mean_array = np.append(mean_array, mean)\n",
        "    \n",
        "             for z in range(len(elements)):\n",
        "                 variance= variance +(elements[z] - mean) ** 2 +1\n",
        "\n",
        "             variance= variance/counter\n",
        "             Cov= (variance**2)\n",
        "             Cov_array=np.append(Cov_array,Cov)\n",
        "   \n",
        "          self.mean_dict[k] = mean_array\n",
        "          average_cov= sum(Cov_array)/len(Cov_array)\n",
        "          average_cov= average_cov*identity\n",
        "          Cov_inverse=np.linalg.inv(average_cov)\n",
        "          self.Cov_dict[k]= average_cov\n",
        "          self.Cov_inv_dict[k]=Cov_inverse\n",
        "  \n",
        "       \n",
        "\n",
        "   def predict(self,X_test):\n",
        "\n",
        "     prediction=[]\n",
        "\n",
        "     for i in range(0,len(X_test)):\n",
        "       current_sample= X_test[i]\n",
        "\n",
        "       for j in range(0,self.classes_num):\n",
        "           mean= self.mean_dict[j]\n",
        "\n",
        "           Cov= self.Cov_dict[j]\n",
        "           Cov_inverse= np.linalg.inv(Cov)  \n",
        "\n",
        "           inter1=np.subtract(current_sample,mean)\n",
        "           inter1=np.transpose(inter1)\n",
        "\n",
        "           inter2= np.matmul(inter1,Cov_inverse)\n",
        "           inter2=np.reshape(inter2,(1,784))\n",
        "\n",
        "\n",
        "           value= np.matmul(inter2,inter1)\n",
        "           d_function= (-0.5)*value\n",
        "           self.discriminant_functions.append(d_function)\n",
        "  \n",
        "       class_num= np.argmax(self.discriminant_functions)\n",
        "       prediction.append(class_num)\n",
        "       self.discriminant_functions=[]\n",
        "\n",
        "    \n",
        "     return prediction\n",
        " \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy Function:"
      ],
      "metadata": {
        "id": "_hU6p5owMr8C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMerkaR4gDzO"
      },
      "outputs": [],
      "source": [
        "def Accuracy(y_pred,y_test):\n",
        "  return np.sum(y_pred == y_test)/len(y_test) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an43X-a9e56R"
      },
      "source": [
        "## Loading Mnist Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ui_NUqKe2rR",
        "outputId": "0c1e5b1c-d4ef-4c0d-d3c2-b1c8d58f86dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "print(type(y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEdTmaTsfJD7"
      },
      "source": [
        "## Preprocessing on the dataset:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTo6Q8UifDeQ",
        "outputId": "28696b26-adb2-487f-852e-40ae1e3aa190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(60000,)\n",
            "(10000, 784)\n"
          ]
        }
      ],
      "source": [
        "X_train= X_train.reshape(X_train.shape[0], 28*28)  #reshaping the data\n",
        "X_test= X_test.reshape(X_test.shape[0], 28*28)\n",
        "\n",
        "X_train = X_train/255     # normalizing data from (0-255) to (0-1) to make it easier for the network to learn\n",
        "X_test = X_test/255 \n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Separating the Training Samples of each Class:"
      ],
      "metadata": {
        "id": "RbFRIdYa8K8_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82rCj6lrECrf"
      },
      "outputs": [],
      "source": [
        "# Separating the Training Samples of each Class into 10 classes\n",
        "\n",
        "class0=[]\n",
        "class1=[]\n",
        "class2=[]\n",
        "class3=[]\n",
        "class4=[]\n",
        "class5=[]\n",
        "class6=[]\n",
        "class7=[]\n",
        "class8=[]\n",
        "class9=[]\n",
        "\n",
        "keys = range(0,10)\n",
        "\n",
        "for key in keys:\n",
        " for i in range(len(y_train)):\n",
        "\n",
        "  if y_train[i] == key and key == 0:\n",
        "    class0.append(X_train[i])\n",
        "  \n",
        "  if y_train[i] == key and key == 1:\n",
        "    class1.append(X_train[i])\n",
        "  \n",
        "  if y_train[i] == key and key == 2:\n",
        "    class2.append(X_train[i])\n",
        "  \n",
        "  if y_train[i] == key and key == 3:\n",
        "    class3.append(X_train[i])\n",
        "  \n",
        "  if y_train[i] == key and key == 4:\n",
        "    class4.append(X_train[i])\n",
        "\n",
        "  if y_train[i] == key and key == 5:\n",
        "    class5.append(X_train[i])\n",
        "  \n",
        "  if y_train[i] == key and key == 6:\n",
        "    class6.append(X_train[i])\n",
        "  \n",
        "  if y_train[i] == key and key == 7:\n",
        "    class7.append(X_train[i])\n",
        "  \n",
        "  if y_train[i] == key and key == 8:\n",
        "    class8.append(X_train[i])\n",
        "  \n",
        "  if y_train[i] == key and key == 9:\n",
        "    class9.append(X_train[i])\n",
        "  \n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making a list of the samples number for each class:\n",
        "As the number of samples is different from a class to another."
      ],
      "metadata": {
        "id": "KGH9tV998g2K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xQv-UoLKs56",
        "outputId": "241f1e58-343f-4b64-d945-9b833e86e23f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]\n"
          ]
        }
      ],
      "source": [
        "samples_num=[]\n",
        "\n",
        "classes=[class0,class1,class2,class3,class4,class5,class6,class7,class8,class9]\n",
        "\n",
        "for i in range(len(classes)):\n",
        "  samples_num.append(len(classes[i]))\n",
        "\n",
        "\n",
        "print(samples_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Training Data Dictionary:\n",
        "Putting the training data in a dictionary where its keys are the number of the classes and the values are the training samples. "
      ],
      "metadata": {
        "id": "nAsjRakC7ZAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data={}\n",
        "\n",
        "for i in range(0,len(classes)):\n",
        "  \n",
        "       training_data[i]= classes[i]"
      ],
      "metadata": {
        "id": "Fg2aEPnc4t6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the Bayesian Classifier with Mnist Dataset: "
      ],
      "metadata": {
        "id": "VhPDFdFD80WV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOzi5Eqm-yAF",
        "outputId": "bf1d2f16-1b33-41da-9498-96077967b7ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy= 82.47 %\n"
          ]
        }
      ],
      "source": [
        "classifier= BayesianClassifier()\n",
        "classifier.fit(training_data,samples_num)\n",
        "y_predict=classifier.predict(X_test)\n",
        "accuracy= Accuracy(y_predict,y_test)\n",
        "print(\"Accuracy=\",accuracy,\"%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix:"
      ],
      "metadata": {
        "id": "XO-978pPKVhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJlMfvAyJcJy",
        "outputId": "692e6f9b-68c9-4568-821a-c9b0b8744b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 880,    0,    8,    2,    0,   58,   24,    1,    7,    0],\n",
              "       [   0, 1075,   17,    4,    0,   14,    3,    0,   22,    0],\n",
              "       [  19,   43,  811,   34,   30,    4,   21,   15,   50,    5],\n",
              "       [   4,   14,   28,  815,    0,   58,    7,   14,   57,   13],\n",
              "       [   1,   12,    6,    0,  812,    5,   21,    1,   12,  112],\n",
              "       [  14,   39,    7,  104,   24,  645,   24,   10,   14,   11],\n",
              "       [  19,   21,   27,    0,   27,   39,  823,    0,    2,    0],\n",
              "       [   3,   49,   27,    2,   18,    5,    0,  850,   16,   58],\n",
              "       [  15,   20,   17,   82,   14,   42,   13,    7,  735,   29],\n",
              "       [  18,   16,   11,   10,   88,   17,    0,   26,   22,  801]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Report:"
      ],
      "metadata": {
        "id": "y4Gt1kXiK2lT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RH7GDeBKrRq",
        "outputId": "b7a3754b-4edf-46d2-91de-3e9ba5c9e399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.90      0.90       980\n",
            "           1       0.83      0.95      0.89      1135\n",
            "           2       0.85      0.79      0.81      1032\n",
            "           3       0.77      0.81      0.79      1010\n",
            "           4       0.80      0.83      0.81       982\n",
            "           5       0.73      0.72      0.73       892\n",
            "           6       0.88      0.86      0.87       958\n",
            "           7       0.92      0.83      0.87      1028\n",
            "           8       0.78      0.75      0.77       974\n",
            "           9       0.78      0.79      0.79      1009\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.82      0.82     10000\n",
            "weighted avg       0.83      0.82      0.82     10000\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}